{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0b214dbc5ee41ad226ce4ad4108ccb9b9d54b01c9d6dc32ea7d254e2f3c6d5529",
   "display_name": "Python 3.9.2  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "b214dbc5ee41ad226ce4ad4108ccb9b9d54b01c9d6dc32ea7d254e2f3c6d5529"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'logs/'\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# Se importan librerías para graficar.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Input\n",
    "import keras.regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_people_num = (df['Outcome'] == 0).sum()\n",
    "sick_people_num = (df['Outcome'] != 0).sum()\n",
    "total = df.shape[0]\n",
    "print(\"Healthy people: \" + str(healthy_people_num))\n",
    "print(\"Sick people: \" + str(sick_people_num))\n",
    "print(\"Total: \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "labels = ['No Diabéticos', 'Diabétos']\n",
    "sizes = [healthy_people_num,sick_people_num]\n",
    "colors = [\"green\",\"red\"]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.pie(sizes, labels=labels, explode= (0.01,0) , colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n",
    "\n",
    "plt.title('Porcentaje de diabéticos.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df2[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.ylabel('Variables')\n",
    "plt.title(\"Boxplots\")\n",
    "ax = sns.boxplot(data = df2, \n",
    "  orient = 'h', \n",
    "  palette = 'Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=df2.columns, y=df2.isnull().sum())\n",
    "plt.xticks(rotation=45);\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(100*p.get_height()/df.shape[0], '.1f') + \"%\", \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df2.corr()\n",
    "correlations['Outcome'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Insulin'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def negative_predictive_value(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return tn / (tn + fn + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    sens_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return sens_keras\n",
    "\n",
    "def positive_predictive_value(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    ppv_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return ppv_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    # Plot the training loss.\n",
    "    plt.plot(history.history['loss'], 'r-')\n",
    "\n",
    "    # Plot the validation loss.\n",
    "    plt.plot(history.history['val_loss'], 'b-')\n",
    "\n",
    "    # X-axis label.\n",
    "    plt.xlabel('Epochs')\n",
    "\n",
    "    # Y-axis label.\n",
    "    plt.ylabel('Cost')\n",
    "\n",
    "    # Graph legend.\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "\n",
    "    # Graph title.\n",
    "    plt.title('Loss Graph')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesPredictor:\n",
    "    def __init__(self, dataframe, name, replaceOutliers=False, deleteRowsWithOutliers=False, replaceNulls=False,deleteRowsWithNulls=False, nullColumns=[], outliersColumns=[], columnsToRemove=[], polyFeatDeg = -1, binsDiscretizer = -1):\n",
    "        \"\"\"DiabetesPredictor\n",
    "\n",
    "    This is a class contains the most part of the methods needed for the diabetes predictor,\n",
    "    first get the data of the csv file and then perform some methods to clean the data insid\n",
    "    and allows you to choose if it has to replace outliers or not and replace nulls values or not.\n",
    "\n",
    "\n",
    "    Attributes:\n",
    "        replace_outliers: Use the string \"replace_outliers\" if you want to do that on your model with the median value\n",
    "        replace_nulls: Use the string \"replace_nulls\" to replace all nulls in your model with the median value\n",
    "        delete_row_with_outliers: Use the string \"delete_row_with_outliers\" to replace all the rows that contains outliers\n",
    "    \"\"\"\n",
    "        self.df = dataframe.copy()\n",
    "        self.name = name\n",
    "\n",
    "        nullCols = nullColumns.copy()\n",
    "        outlierCols = outliersColumns.copy()\n",
    "\n",
    "        self.__remove_columns__(columnsToRemove)\n",
    "        \n",
    "        nullCols = [n for n in nullColumns if n not in columnsToRemove]\n",
    "        outlierCols = [out for out in outliersColumns if out[0] not in columnsToRemove]\n",
    "\n",
    "        if (replaceNulls or deleteRowsWithNulls):\n",
    "            self.df[nullCols] = self.df[nullCols].replace(0,np.NaN)\n",
    "\n",
    "        if(replaceOutliers):\n",
    "            self.__replace_outliers__(outlierCols)\n",
    "        elif(deleteRowsWithOutliers): \n",
    "            self.__delete_row_with_outliers__(outlierCols)\n",
    "\n",
    "        if(replaceNulls):\n",
    "            self.__replace_nulls__(nullCols)\n",
    "        elif (deleteRowsWithNulls):\n",
    "            self.__delete_row_with_nulls__(nullCols)\n",
    "\n",
    "        self.__separate_data_and_labels__()\n",
    "\n",
    "        if (polyFeatDeg > 0):\n",
    "            poly = PolynomialFeatures(degree=polyFeatDeg)\n",
    "            self.x = poly.fit_transform(self.x)\n",
    "\n",
    "        if (binsDiscretizer > 1):\n",
    "            disc = KBinsDiscretizer(n_bins=binsDiscretizer, encode='ordinal', strategy='uniform')\n",
    "            self.x = disc.fit_transform(self.x)\n",
    "\n",
    "        self.__normalize_data__()\n",
    "        self.__split_train_val__()\n",
    "\n",
    "    def __separate_data_and_labels__(self):\n",
    "        df_values = self.df.values\n",
    "        self.x = df_values[:,:-1]\n",
    "        self.y = df_values[:, -1].reshape(self.x.shape[0], 1)\n",
    "\n",
    "    def __normalize_data__(self):\n",
    "        # Mean, columnar axis.\n",
    "        x_mean = np.mean(self.x, axis=0, keepdims=True)\n",
    "        # Std. Deviation, columnar axis.\n",
    "        x_std = np.std(self.x, axis=0, keepdims=True)\n",
    "        # Normalizing.\n",
    "        self.x = (self.x - x_mean)/x_std\n",
    "    \n",
    "    def __replace_outliers__(self, cols):\n",
    "        #Para cada columna (excepto para el Outcome) se reemplazan los outliers por su mediana.\n",
    "        if(cols == []):\n",
    "            for col in self.df.columns:\n",
    "                cols.append([col, np.Infinity, 0])\n",
    "        for col in cols:\n",
    "            Upper_val, Lower_val, med = self.__get_outliers_limits__(col)\n",
    "            #Reemplazo.\n",
    "            for i in self.df[col[0]]:\n",
    "                if i > Upper_val or i < Lower_val:\n",
    "                    self.df[col[0]] = self.df[col[0]].replace(i, med)\n",
    "\n",
    "    def __get_outliers_limits__(self, col, want_med = True):\n",
    "        #Cálculo de parámetros para obtener los outliers.\n",
    "        q1 = self.df[col[0]].quantile(0.25)\n",
    "        q3 = self.df[col[0]].quantile(0.75)\n",
    "        iqr = q3-q1\n",
    "        #Límites de los valores tipicos.\n",
    "        Lower_tail = q1 - 1.5 * iqr\n",
    "        Upper_tail = q3 + 1.5 * iqr\n",
    "\n",
    "        Lower_val = min(Lower_tail, col[1])\n",
    "        Upper_val = max(Upper_tail, col[2])\n",
    "        #Cálculo de la mediana.\n",
    "        med = np.median(self.df[col[0]])\n",
    "        if(want_med == True):\n",
    "            return Upper_val, Lower_val, med\n",
    "        else:\n",
    "            return Upper_val, Lower_val\n",
    "\n",
    "    def __replace_nulls__(self, cols):\n",
    "        columns = cols\n",
    "        median=self.df[columns].median()\n",
    "        self.df[columns]=self.df[columns].replace(np.NaN,median)\n",
    "\n",
    "    def __remove_columns__(self, cols):\n",
    "        self.df = self.df.drop(cols, axis=1)\n",
    "    \n",
    "    def __split_train_val__(self):\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.x, self.y, test_size=0.1, random_state=5)\n",
    "\n",
    "    def __model_builder__(self,hp):\n",
    "        model = Sequential()\n",
    "        initializer = tf.keras.initializers.GlorotNormal(seed=7)\n",
    "        model.add(Dense(1, kernel_initializer=initializer, activation='sigmoid', input_shape=(self.x.shape[1],)))\n",
    "\n",
    "        # Tune the learning rate for the optimizer\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        hp_momentum = hp.Choice('momentum',values=[0.9, 0.99, 0.999])\n",
    "        hp_learning_rate = hp.Float('learning_rate', 1e-5, 1.0, sampling='log', default=1e-3)\n",
    "        \n",
    "\n",
    "        model.compile(optimizer=optimizers.SGD(momentum=hp_momentum, learning_rate=hp_learning_rate, ),\n",
    "                        loss=keras.losses.BinaryCrossentropy(),\n",
    "                        metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def __find_best_hyperparams__(self):\n",
    "        log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
    "        hist_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            embeddings_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq='batch')\n",
    "        self.tuner = kt.Hyperband(self.__model_builder__,\n",
    "                     kt.Objective(\"val_loss\", direction=\"min\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     executions_per_trial=3,\n",
    "                     project_name=self.name,\n",
    "                     directory='saved_models'\n",
    "                     )\n",
    "        self.tuner.search(self.x_train, self.y_train, epochs=100, validation_data = (self.x_val, self.y_val), use_multiprocessing=True)\n",
    "        self.best_hps=self.tuner.get_best_hyperparameters(num_trials=2)[0]\n",
    "\n",
    "    def get_best_hyperparams(self):\n",
    "        return 'Learning Rate: ' + str(self.best_hps.get('learning_rate')) + '   --   Momentum: ' + str(self.best_hps.get('momentum'))\n",
    "\n",
    "    def train_model(self):\n",
    "        self.__find_best_hyperparams__()\n",
    "        model = self.tuner.hypermodel.build(self.best_hps)\n",
    "        history = model.fit(self.x_train, self.y_train, epochs=100, validation_data = (self.x_val, self.y_val), verbose=0)\n",
    "        plot_loss(history)\n",
    "        val_acc_per_epoch = history.history['val_loss']\n",
    "        best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1\n",
    "        print('Best epoch: %d' % (best_epoch,))\n",
    "        #plot_loss(history)\n",
    "        self.hypermodel = self.tuner.hypermodel.build(self.best_hps)\n",
    "        # Retrain the model\n",
    "        self.hypermodel.fit(self.x_train, self.y_train, epochs=best_epoch, validation_data = (self.x_val, self.y_val))\n",
    "\n",
    "    def validate_model(self):\n",
    "        self.predictions = self.hypermodel(self.x_val)\n",
    "        self.fpr_keras, self.tpr_keras, self.thresholds_keras = roc_curve(self.y_val, self.predictions)\n",
    "        self.auc_keras = auc(self.fpr_keras, self.tpr_keras)\n",
    "        return self.auc_keras\n",
    "\n",
    "    def plot_roc(self):\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(self.fpr_keras, self.tpr_keras, label='Keras (area = {:.3f})'.format(self.auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    def get_metrics(self):\n",
    "        print('AUC ' + str(self.auc_keras))\n",
    "        rounded_preds = np.rint(self.predictions)\n",
    "        print('Specificity: ' + str(specificity(self.y_val.astype(float),  rounded_preds.astype(float))))\n",
    "        print('Sensitivity: ' + str(sensitivity(self.y_val.astype(float),  rounded_preds.astype(float))))\n",
    "        print('Positive Predictive Value: ' + str(positive_predictive_value(self.y_val.astype(float), rounded_preds.astype(float))))\n",
    "        print('Negative Predictive Value: ' + str(negative_predictive_value(self.y_val.astype(float), rounded_preds.astype(float))))\n",
    "    \n",
    "    def __delete_row_with_outliers__(self, cols):\n",
    "        #Para cada columna (excepto para el Outcome) se buscan los outliers para borrar la fila\n",
    "        if(cols == []):\n",
    "            for col in self.df.columns:\n",
    "                cols.append([col, np.Infinity, 0])\n",
    "        for col in cols:\n",
    "            Upper_val, Lower_val, med = self.__get_outliers_limits__(col)\n",
    "            self.df = self.df[(Lower_val < self.df[col[0]]) & (self.df[col[0]] < Upper_val)]\n",
    "\n",
    "    def __delete_row_with_nulls__(self, cols):\n",
    "        for col in cols:\n",
    "            self.df = self.df[pd.notnull(self.df[col])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DiabetesPredictor(train_df,'predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pred = predictor.validate_model()\n",
    "print('AUC: ' + str(auc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.plot_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.get_metrics()"
   ]
  },
  {
   "source": [
    "## Limpiando Datos\n",
    "#### Reemplazando Nulls por la mediana"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepNulls = DiabetesPredictor(train_df,'rep_nulls_predictor' ,replaceNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'])\n",
    "predictorRepNulls.train_model()\n",
    "aucRepNulls = predictorRepNulls.validate_model()\n",
    "print('AUC: ' + str(aucRepNulls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepNulls.get_best_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepNulls.plot_roc()\n",
    "predictorRepNulls.get_metrics()"
   ]
  },
  {
   "source": [
    "#### Removiendo Nulls"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRemNulls = DiabetesPredictor(train_df,'rem_nulls_predictor' ,deleteRowsWithNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'])\n",
    "predictorRemNulls.train_model()\n",
    "aucRemNulls = predictorRemNulls.validate_model()\n",
    "print('AUC: ' + str(aucRemNulls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRemNulls.plot_roc()\n",
    "predictorRemNulls.get_metrics()"
   ]
  },
  {
   "source": [
    "#### Removiendo Outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRemOutliers = DiabetesPredictor(train_df,'rem_outliers_predictor' ,deleteRowsWithNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'], deleteRowsWithOutliers=True, outliersColumns=[['BMI', 18.5, 50],['BloodPressure',40,120],['SkinThickness', np.Infinity, 0], ['Pregnancies',np.Infinity,0]])\n",
    "predictorRemOutliers.train_model()\n",
    "aucRemOut = predictorRemOutliers.validate_model()\n",
    "print('AUC: ' + str(aucRemOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRemOutliers.plot_roc()\n",
    "predictorRemOutliers.get_metrics()"
   ]
  },
  {
   "source": [
    "#### Reemplazando Outliers\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepOutliers = DiabetesPredictor(train_df,'rep_outliers_predictor' ,deleteRowsWithNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'], replaceOutliers=True, outliersColumns=[['BMI', 18.5, 50],['BloodPressure',40,120], ['Pregnancies',np.Infinity,0]])\n",
    "predictorRepOutliers.train_model()\n",
    "aucRepOut = predictorRepOutliers.validate_model()\n",
    "print('AUC: ' + str(aucRepOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepOutliers.plot_roc()\n",
    "predictorRepOutliers.get_metrics()"
   ]
  },
  {
   "source": [
    "#### Removiendo Columnas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAuc = aucRemNulls\n",
    "tryRemovingCols = ['BloodPressure', 'Age', 'DiabetesPedigreeFunction', 'Pregnancies', 'SkinThickness']\n",
    "removeCols = []\n",
    "removeColsAuc = []\n",
    "nullCols = ['Glucose','BloodPressure','SkinThickness','BMI']\n",
    "\n",
    "for col in tryRemovingCols:\n",
    "\tprint(col)\n",
    "\tpred = DiabetesPredictor(df, col, deleteRowsWithNulls=True, nullColumns=nullCols, columnsToRemove=[col],)\n",
    "\tpred.train_model()\n",
    "\taucR = pred.validate_model()\n",
    "\tif (aucR>bestAuc):\n",
    "\t\tremoveCols.append(col)\n",
    "\t\tremoveColsAuc.append(aucR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removeCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPred = DiabetesPredictor(df,'final' ,deleteRowsWithNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'],  columnsToRemove=removeCols, replaceOutliers=True, outliersColumns=[['BMI', 18.5, 50],['BloodPressure',40,120], ['Pregnancies',np.Infinity,0]])\n",
    "finalPred.train_model()\n",
    "aucFinal = finalPred.validate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: ' + str(aucFinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPred.plot_roc()\n",
    "finalPred.get_metrics()"
   ]
  }
 ]
}