{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0b214dbc5ee41ad226ce4ad4108ccb9b9d54b01c9d6dc32ea7d254e2f3c6d5529",
   "display_name": "Python 3.9.2  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "b214dbc5ee41ad226ce4ad4108ccb9b9d54b01c9d6dc32ea7d254e2f3c6d5529"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorboard\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir 'logs/'\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# Se importan librerías para graficar.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Activation, Input, Dropout\n",
    "from keras import regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_people_num = (df['Outcome'] == 0).sum()\n",
    "sick_people_num = (df['Outcome'] != 0).sum()\n",
    "total = df.shape[0]\n",
    "print(\"Healthy people: \" + str(healthy_people_num))\n",
    "print(\"Sick people: \" + str(sick_people_num))\n",
    "print(\"Total: \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "labels = ['No Diabéticos', 'Diabétos']\n",
    "sizes = [healthy_people_num,sick_people_num]\n",
    "colors = [\"green\",\"red\"]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.pie(sizes, labels=labels, explode= (0.01,0) , colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n",
    "\n",
    "plt.title('Porcentaje de diabéticos.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df2[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.ylabel('Variables')\n",
    "plt.title(\"Boxplots\")\n",
    "ax = sns.boxplot(data = df2, \n",
    "  orient = 'h', \n",
    "  palette = 'Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(x=df2.columns, y=df2.isnull().sum())\n",
    "plt.xticks(rotation=45);\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(100*p.get_height()/df.shape[0], '.1f') + \"%\", \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 10), \n",
    "                   textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df2.corr()\n",
    "correlations['Outcome'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Insulin'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "msk = np.random.rand(len(df)) < 0.9\n",
    "train_val_df = df[msk]\n",
    "testData = df[~msk]\n",
    "\n",
    "mskVal = np.random.rand(len(train_val_df)) < 0.9\n",
    "trainData = train_val_df[mskVal]\n",
    "validationData = train_val_df[~mskVal]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def separate_data_and_labels(df):\n",
    "        data = df.copy()\n",
    "        y_values = data[data.columns[-1]].values.reshape(data.shape[0], 1)\n",
    "        data = data.drop([data.columns[-1]], axis=1)\n",
    "        return data, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data, y_train_values = separate_data_and_labels(trainData)\n",
    "x_val_data, y_val_values = separate_data_and_labels(validationData)\n",
    "x_test_data, y_test_values = separate_data_and_labels(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(testData)\n",
    "del(validationData)\n",
    "del(trainData)\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def negative_predictive_value(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return tn / (tn + fn + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    sens_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return sens_keras\n",
    "\n",
    "def positive_predictive_value(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    ppv_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return ppv_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    # Plot the training loss.\n",
    "    plt.plot(history.history['loss'], 'r-')\n",
    "\n",
    "    # Plot the validation loss.\n",
    "    plt.plot(history.history['val_loss'], 'b-')\n",
    "\n",
    "    # X-axis label.\n",
    "    plt.xlabel('Epochs')\n",
    "\n",
    "    # Y-axis label.\n",
    "    plt.ylabel('Cost')\n",
    "\n",
    "    # Graph legend.\n",
    "    plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "\n",
    "    # Graph title.\n",
    "    plt.title('Loss Graph')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesPredictor:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"DiabetesPredictor\n",
    "\n",
    "    This is a class contains the most part of the methods needed for the diabetes predictor,\n",
    "    first get the data of the csv file and then perform some methods to clean the data insid\n",
    "    and allows you to choose if it has to replace outliers or not and replace nulls values or not.\n",
    "\n",
    "    \"\"\"\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, train_df, y_train, val_df, y_val, replaceOutliers=False, replaceNulls=False, nullColumns=[], outliersColumnsMap={}, columnsToRemove=[], polyFeatDeg = -1, binsDiscretizer = -1, earlyStop = False, dropOut = False, regu = False, batchNormalization = False):\n",
    "        train_dataframe = train_df.copy()\n",
    "\n",
    "        self.columnsToRemove = columnsToRemove.copy()\n",
    "        self.nullCols = nullColumns.copy()\n",
    "        self.replaceNulls = replaceNulls\n",
    "        self.replaceOutliers = replaceOutliers\n",
    "        self.polyFeatDeg = polyFeatDeg\n",
    "        self.binsDiscretizer = binsDiscretizer\n",
    "        self.earlyStop = earlyStop\n",
    "        self.dropOut = dropOut\n",
    "        self.regu = regu\n",
    "        self.best_hps = None\n",
    "        self.batchNormalization = batchNormalization\n",
    "\n",
    "        self.replace_values_nulls = []\n",
    "        self.replace_values_outliers = []\n",
    "        self.outliersLimits = []\n",
    "\n",
    "        self.nullCols = [n for n in self.nullCols if n not in self.columnsToRemove]\n",
    "        self.outlierCols = {}\n",
    "        for k in outliersColumnsMap:\n",
    "            if k not in self.columnsToRemove:\n",
    "                self.outlierCols[k] = outliersColumnsMap[k].copy()\n",
    "\n",
    "        train_dataframe = self.__preprocess_data__(train_dataframe, training=True)\n",
    "\n",
    "        x_train_values = train_dataframe.values\n",
    "        y_train_values = y_train.copy()\n",
    "\n",
    "        self.input_shape = x_train_values.shape\n",
    "\n",
    "        x_val_df = val_df.copy()\n",
    "        x_val_df = self.__preprocess_data__(x_val_df)\n",
    "        x_val_values = x_val_df.values\n",
    "        y_val_values = y_val.copy()\n",
    "\n",
    "        self.hypermodel = self.__tune_hyperparams__(x_train_values, y_train_values, x_val_values,y_val_values)\n",
    "\n",
    "        return self.evaluate(x_val_df, y_val_values, testing = False)\n",
    "        \n",
    "    def __preprocess_data__(self, data, training = False):\n",
    "        df = data.copy()\n",
    "        df = self.__remove_columns__(df)\n",
    "\n",
    "        if self.replaceNulls:\n",
    "            df[self.nullCols] = df[self.nullCols].replace(0,np.NaN)\n",
    "\n",
    "        if training:\n",
    "            self.replace_values_outliers = self.__get_cols_median__(df)\n",
    "            self.outliersLimits = self.__get_outliers_limits__(df)\n",
    "\n",
    "        if(self.replaceOutliers):\n",
    "            df = self.__replace_outliers__(df)\n",
    "\n",
    "        if training:\n",
    "            self.replace_values_nulls = self.__get_cols_median__(df)\n",
    "\n",
    "        if(self.replaceNulls):\n",
    "            df = self.__replace_nulls__(df)\n",
    "\n",
    "        if (self.polyFeatDeg > 0):\n",
    "            poly = PolynomialFeatures(degree=self.polyFeatDeg)\n",
    "            polyArray = poly.fit_transform(df)\n",
    "            c = poly.get_feature_names(df.columns)\n",
    "            df = pd.DataFrame(polyArray, columns = c)\n",
    "\n",
    "        if (self.binsDiscretizer > 1):\n",
    "            disc = KBinsDiscretizer(n_bins=self.binsDiscretizer, encode='ordinal', strategy='uniform')\n",
    "            df = disc.fit_transform(df)\n",
    "\n",
    "        if training:\n",
    "            self.mean_cols = self.__get_cols_mean__(df)\n",
    "            self.std_cols = self.__get_cols_std__(df)\n",
    "\n",
    "        df = self.__normalize_data__(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __get_cols_mean__(self, data):\n",
    "        meandf = data.mean(axis = 0)\n",
    "        meandf.columns = data.columns\n",
    "        return meandf\n",
    "\n",
    "    def __get_cols_std__(self, data):\n",
    "        stddf= data.std(axis = 0)\n",
    "        stddf.columns = data.columns\n",
    "        return stddf\n",
    "\n",
    "    def __get_cols_median__(self, data):\n",
    "        mediandf = data.median(axis = 0)\n",
    "        mediandf.columns = data.columns\n",
    "        return mediandf\n",
    "\n",
    "    def __get_outliers_limits__(self, data):\n",
    "        df = pd.DataFrame(np.zeros((1,len(data.columns))), columns=data.columns)\n",
    "        df = df.astype('object')\n",
    "        for col in data.columns:\n",
    "            col_min = 0\n",
    "            col_max = np.Infinity\n",
    "            if (col in self.outlierCols):\n",
    "                #Cálculo de parámetros para obtener los outliers.\n",
    "                q1 = data[col].quantile(0.25)\n",
    "                q3 = data[col].quantile(0.75)\n",
    "                iqr = q3-q1\n",
    "                #Límites de los valores tipicos.\n",
    "                lower_tail = q1 - 1.5 * iqr\n",
    "                upper_tail = q3 + 1.5 * iqr\n",
    "\n",
    "                col_min = min(lower_tail, self.outlierCols[col][0])\n",
    "                col_max = max(upper_tail,self.outlierCols[col][1])\n",
    "            lims = [col_min, col_max]\n",
    "            df[col][0] = lims\n",
    "        return df\n",
    "\n",
    "    def __replace_outliers__(self, dataframe):\n",
    "        #Para cada columna (excepto para el Outcome) se reemplazan los outliers por su mediana.\n",
    "        df = dataframe.copy()\n",
    "        for col in df.columns:\n",
    "            out_min = self.outliersLimits[col][0][0]\n",
    "            out_max = self.outliersLimits[col][0][1]\n",
    "            for i in df[col]:\n",
    "                if i > out_max or i < out_min:\n",
    "                    df[col] = df[col].replace(i, self.replace_values_outliers[col])\n",
    "        return df\n",
    "\n",
    "    def __replace_nulls__(self, dataframe):\n",
    "        df = dataframe.copy()\n",
    "        for col in self.nullCols:\n",
    "            df[col]=df[col].replace(np.NaN, self.replace_values_nulls[col])\n",
    "        return df\n",
    "\n",
    "    def __normalize_data__(self, dataframe):\n",
    "        # Mean, columnar axis.\n",
    "        df = dataframe.copy()\n",
    "        for col in df.columns:\n",
    "            if (self.std_cols[col] != 0):\n",
    "                df[col] = (df[col] - self.mean_cols[col]) / self.std_cols[col]\n",
    "            else:\n",
    "                df[col] = 0\n",
    "        return df\n",
    "\n",
    "    def __remove_columns__(self, dataframe):\n",
    "        df = dataframe.copy()\n",
    "        df = df.drop(self.columnsToRemove, axis=1)\n",
    "        return df\n",
    "\n",
    "    def __model_builder__(self,hp):\n",
    "        model = Sequential()\n",
    "        initializer = tf.keras.initializers.GlorotNormal(seed=7)\n",
    "\n",
    "        if(self.dropOut):\n",
    "            model.add(Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.5),input_shape=(self.input_shape[1],)))\n",
    "            model.add(Dense(1, kernel_initializer=initializer, activation='sigmoid'))\n",
    "        elif(self.regu):\n",
    "            reg = reg_wrapper(hp.Choice('type', ['l1', 'l2']), hp.Choice('reg_value', [0.01,0.001,0.1,0.005,0.05]))\n",
    "            model.add(Dense(1, kernel_initializer=initializer,kernel_regularizer=reg, activation='sigmoid', input_shape=(self.input_shape[1],)))\n",
    "        elif (self.batchNormalization):\n",
    "            model.add(BatchNormalization(input_shape=(self.input_shape[1],)))\n",
    "            model.add(Dense(1, kernel_initializer=initializer, activation='sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(1, kernel_initializer=initializer, activation='sigmoid', input_shape=(self.input_shape[1],)))\n",
    "\n",
    "        \n",
    "        # Tune the learning rate for the optimizer\n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        #hp_momentum = hp.Choice('momentum',values=[0.9, 0.99, 0.999])\n",
    "        hp_learning_rate= hp.Float(\n",
    "            'learning_rate',\n",
    "            min_value=1e-5,\n",
    "            max_value=1e-2,\n",
    "            sampling='LOG',\n",
    "            default=1e-3\n",
    "        )\n",
    "        hp_momentum = hp.Choice('momentum',values=[0.9, 0.99, 0.999])\n",
    "        hp_decay = hp.Float('decay', 1e-5, 1e-3, sampling='log', default=1e-4)\n",
    "\n",
    "        model.compile(optimizer=optimizers.SGD(learning_rate=hp_learning_rate, momentum=hp_momentum, decay = hp_decay),\n",
    "                        loss=keras.losses.BinaryCrossentropy(),\n",
    "                        metrics=[tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "\n",
    "    def __tune_hyperparams__(self, x_train, y_train, x_val, y_val):\n",
    "        # log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%m%d-%H%M\")\n",
    "        # hist_callback = tf.keras.callbacks.TensorBoard(\n",
    "        #     log_dir=log_dir,\n",
    "        #     histogram_freq=1,\n",
    "        #     embeddings_freq=1,\n",
    "        #     write_graph=True,\n",
    "        #     update_freq='batch')\n",
    "        tuner = kt.Hyperband(self.__model_builder__,\n",
    "                     kt.Objective(\"val_auc\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     seed = 4,\n",
    "                     executions_per_trial=3,\n",
    "                     project_name=self.name,\n",
    "                     directory='saved_models'\n",
    "                     )\n",
    "        stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "        #### Search for HyperParams #####\n",
    "        if (self.earlyStop):\n",
    "            tuner.search(x_train, y_train, epochs=125, validation_data = (x_val, y_val), callbacks=[stop_early], use_multiprocessing=True, verbose=2)\n",
    "        else:\n",
    "            tuner.search(x_train, y_train, epochs=125, validation_data = (x_val, y_val), use_multiprocessing=True, verbose=2)\n",
    "\n",
    "        # Get the optimal hyperparameters\n",
    "        self.best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "        # Build the model with the optimal hyperparameters and train it on the data\n",
    "        model = tuner.hypermodel.build(self.best_hps)\n",
    "        if (self.earlyStop):\n",
    "            history = model.fit(x_train, y_train, epochs=125, validation_data = (x_val, y_val),callbacks=[stop_early], verbose=0)\n",
    "        else:\n",
    "            history = model.fit(x_train, y_train, epochs=125, validation_data = (x_val, y_val), verbose=0)\n",
    "\n",
    "        # Plot Loss\n",
    "        plot_loss(history)\n",
    "\n",
    "        # Find optimal Epocs\n",
    "        val_acc_per_epoch = history.history['val_auc']\n",
    "        best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "\n",
    "        # Build and Retrain the model with best Epochs\n",
    "        hypermodel = tuner.hypermodel.build(self.best_hps)\n",
    "        if (self.earlyStop):\n",
    "            hypermodel.fit(x_train, y_train, epochs=best_epoch,callbacks=[stop_early], validation_data = (x_val, y_val), verbose=0)\n",
    "        else:\n",
    "            hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_data = (x_val, y_val), verbose=0)\n",
    "\n",
    "        # Return trained model\n",
    "        return hypermodel\n",
    "\n",
    "    def evaluate(self, x_val_df, y_val, testing=True):\n",
    "        x_df = x_val_df.copy()\n",
    "        predictions, rounded_preds = self.predict(x_df, testing=testing)\n",
    "\n",
    "        fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_val, predictions)\n",
    "        auc_keras = auc(fpr_keras, tpr_keras)\n",
    "        spe = specificity(y_val.astype(float),  rounded_preds.astype(float))\n",
    "        sen = sensitivity(y_val.astype(float),  rounded_preds.astype(float))\n",
    "        ppv = positive_predictive_value(y_val.astype(float), rounded_preds.astype(float))\n",
    "        npv = negative_predictive_value(y_val.astype(float), rounded_preds.astype(float))\n",
    "\n",
    "        self.plot_roc(fpr_keras, tpr_keras, auc_keras)\n",
    "\n",
    "        print('AUC ' + str(auc_keras))\n",
    "        print('Specificity: ' + str(spe))\n",
    "        print('Sensitivity: ' + str(sen))\n",
    "        print('Positive Predictive Value: ' + str(ppv))\n",
    "        print('Negative Predictive Value: ' + str(npv))\n",
    "\n",
    "        return auc_keras, spe, sen, ppv, npv\n",
    "\n",
    "    def predict(self, x_val_df, testing=True):\n",
    "        x_df = x_val_df.copy()\n",
    "        if (testing):\n",
    "            x_df = self.__preprocess_data__(x_df)\n",
    "        predictions = self.hypermodel(x_df.values)\n",
    "        rounded_preds = np.rint(predictions)\n",
    "        return predictions, rounded_preds\n",
    "\n",
    "    def plot_roc(self, fpr_keras, tpr_keras, auc_keras):\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.plot(fpr_keras, tpr_keras, label=' (Area = {:.3f})'.format(auc_keras))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve ' + self.name)\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = DiabetesPredictor('predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " aucPred, spePred, senPred, ppvPred, npvPred = predictor.fit(x_train_data, y_train_values, x_val_data, y_val_values)"
   ]
  },
  {
   "source": [
    "## Limpiando Datos\n",
    "#### Reemplazando Nulls por la mediana"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepNulls = DiabetesPredictor('rep_nulls_predictor')\n",
    "aucRepNulls, speRepNulls, senRepNulls, ppvRepNulls, npvRepNulls = predictorRepNulls.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'])"
   ]
  },
  {
   "source": [
    "#### Reemplazando Outliers\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepOutliers = DiabetesPredictor('rep_outliers_predictor')\n",
    "aucRepOut, speRepOut, senRepOut, ppvRepOut, npvRepOut = predictorRepOutliers.fit(x_train_data, y_train_values, x_val_data, y_val_values, replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]})"
   ]
  },
  {
   "source": [
    "#### Reemplazando Outliers y nulls\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorRepOutliersAndNulls = DiabetesPredictor('rep_outliers_nulls_predictor')\n",
    "aucRepOutN, speRepOutN, senRepOutN, ppvRepOutN, npvRepOutN = predictorRepOutliersAndNulls.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceNulls=True, nullColumns=['Glucose','BloodPressure','SkinThickness','BMI'], replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]})\n"
   ]
  },
  {
   "source": [
    "#### Removiendo Columnas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAuc = aucRepOut\n",
    "tryRemovingCols = ['BloodPressure', 'Age', 'DiabetesPedigreeFunction', 'Pregnancies', 'SkinThickness']\n",
    "removeCols = []\n",
    "removeColsAuc = []\n",
    "nullCols = ['Glucose','BloodPressure','SkinThickness','BMI']\n",
    "\n",
    "for col in tryRemovingCols:\n",
    "\tprint(col)\n",
    "\tpred = DiabetesPredictor(col)\n",
    "\taucR, speR, senR, ppvR, npvR = pred.fit(x_train_data, y_train_values, x_val_data, y_val_values, replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[col])\n",
    "\tif (aucR>bestAuc):\n",
    "\t\tremoveCols.append(col)\n",
    "\t\tremoveColsAuc.append(aucR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removeCols)\n",
    "print(removeColsAuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remColsCombPred = DiabetesPredictor('remColsCombPred')\n",
    "# aucRCCP, speRCCP, senRCCP, ppvRCCP, npvRCCP = remColsCombPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=removeCols)"
   ]
  },
  {
   "source": [
    "#### Sacando solo SkinThickness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remSkinPred = DiabetesPredictor('remSkinPred')\n",
    "aucRS, speRS, senRS, ppvRS, npvRS = remSkinPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"SkinThickness\"])\n"
   ]
  },
  {
   "source": [
    "### Con PolynomialFeatures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucPolys = []\n",
    "for i in range(1,5):\n",
    "    polyPred = DiabetesPredictor('featPol' + str(i))\n",
    "\n",
    "    aucPoly, spePoly, senPoly, ppvPoly, npvPoly = polyPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'BloodPressure':[40,120], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"SkinThickness\"], polyFeatDeg = i)\n",
    "    aucPolys.append(aucPoly)\n",
    "\n",
    "bestPolDeg = aucPolys.index(max(aucPolys)) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aucPolys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Degree: ' + str(bestPolDeg) + \" --- AUC: \" + str(max(aucPolys)))"
   ]
  },
  {
   "source": [
    "#### Con EarlyStopping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyPred = DiabetesPredictor('earlyPred')\n",
    "aucEarly, speEarly, senEarly, ppvEarly, npvEarly = earlyPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"BloodPressure\"], polyFeatDeg = bestPolDeg, earlyStop = True)"
   ]
  },
  {
   "source": [
    "#### Con DropOut"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropPred = DiabetesPredictor('dropPred')\n",
    "aucDrop, speDrop, senDrop, ppvDrop, npvDrop = dropPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"BloodPressure\"], polyFeatDeg = bestPolDeg, earlyStop = False, dropOut = True)"
   ]
  },
  {
   "source": [
    "#### Con Regularizadores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_wrapper(type, value):\n",
    "    if type == 'l2':\n",
    "        return regularizers.l2(value)\n",
    "    if type == 'l1':\n",
    "        return regularizers.l1(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reguPred = DiabetesPredictor('reguPred')\n",
    "aucRegu, speRegu, senRegu, ppvRegu, npvRegu = reguPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"BloodPressure\"], polyFeatDeg = bestPolDeg, earlyStop = False, regu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reguPred.best_hps.values"
   ]
  },
  {
   "source": [
    "#### Con Batch Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchPred = DiabetesPredictor('batchPred')\n",
    "aucBatch, speBatch, senBatch, ppvBatch, npvBatch = batchPred.fit(x_train_data, y_train_values, x_val_data, y_val_values,replaceOutliers=True, outliersColumnsMap={'BMI': [18.5, 50],'SkinThickness': [0, np.Infinity], 'Pregnancies': [0, np.Infinity]}, columnsToRemove=[\"BloodPressure\"], polyFeatDeg = bestPolDeg, earlyStop = False, batchNormalization = True)"
   ]
  }
 ]
}