{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd02e9b17fcae5ef2adabbb4e250195cab55342c7a72a8203d10a72d4fc2df4d923",
   "display_name": "Python 3.8.5  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "2e9b17fcae5ef2adabbb4e250195cab55342c7a72a8203d10a72d4fc2df4d923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "## Implementacion de una red neuronal que incorpora una regresión lineal.\n",
    "\n",
    "### Importamos los datos en un dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "source": [
    "Breve Análisis del dataset\n",
    "Mostramos primero algunos valores de nuestro dataset.\n",
    "\n",
    "Luego los nombres de las columnas de nuestro dataframe\n",
    "\n",
    "Y para finalizar tambien mostramos el tamaño del dataframe con el que trabajaremos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Next the first rows of our dataset are showed: \n\n   age     sex     bmi  children smoker     region      charges\n0   19  female  27.900         0    yes  southwest  16884.92400\n1   18    male  33.770         1     no  southeast   1725.55230\n2   28    male  33.000         3     no  southeast   4449.46200\n3   33    male  22.705         0     no  northwest  21984.47061\n4   32    male  28.880         0     no  northwest   3866.85520\n\nThe colums of our dataset refears to: \nIndex(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n\nthe size of the dataframe is: \n (1338, 7)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Next the first rows of our dataset are showed: \\n\")\n",
    "print(df.head())\n",
    "print(\"\\nThe colums of our dataset refears to: \\n\"+str(df.columns) + \"\\n\")\n",
    "print(\"the size of the dataframe is: \\n \" + str(df.shape) + \"\\n\")"
   ]
  },
  {
   "source": [
    "Con la siguiente linea nos fijamos los tipos de datos que tenemos presentes en cada columna\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "Verificamos la cantidad de datos nulos presentes en nuestro dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "Podemos utilizar el método describe para examinar como son los valores que se presentan dentro del dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>39.207025</td>\n      <td>30.663397</td>\n      <td>1.094918</td>\n      <td>13270.422265</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.049960</td>\n      <td>6.098187</td>\n      <td>1.205493</td>\n      <td>12110.011237</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n      <td>15.960000</td>\n      <td>0.000000</td>\n      <td>1121.873900</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27.000000</td>\n      <td>26.296250</td>\n      <td>0.000000</td>\n      <td>4740.287150</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>39.000000</td>\n      <td>30.400000</td>\n      <td>1.000000</td>\n      <td>9382.033000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>51.000000</td>\n      <td>34.693750</td>\n      <td>2.000000</td>\n      <td>16639.912515</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>64.000000</td>\n      <td>53.130000</td>\n      <td>5.000000</td>\n      <td>63770.428010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "### Breve análisis del dataframe\n",
    "\n",
    "De ver los valores que devuelve describe podemos darnos cuenta que como los valores minimos de edad no son 0 entonces no hay datos nulos ni ceros que podrían se considerados invalidos en esa columna, de hecho el valor maximo es 64 por lo que podríamos plantear a priori que no es necesario una limpieza de los datos para esa columna.\n",
    "Luego en el BMI vemos que no existen valores iguales a 0 de hecho el valor minimo es 15 lo cual es un valor posible y el valor maximo es 53 lo cual es un valor muy alto pero al ser el valor mas alto de nuestro dataframe podríamos considerar que esta \"bien\" y que luego será el diagrama de caja el que nos termine de definir si pertenece o no al grupo de los outlayers, pero en principio uno podría afirmar que el valor es posible en un humano, muy poco saludable pero posible. \n",
    "La cantidad de hijos tambien es un parámetro que no presenta valores nulos ni invalidos, debido a que el minimo es cero el cual es un valor perfectamente posible y el valor maximo es 5 lo cual tambien parecería ser un valor esperado, por lo tanto no es necesario realizar ningun tipo de limpieza de datos sobre el mismo.\n",
    "Los charges que son sobrados por la atencion medica recibida en principio tampoco tienen valores nulos ni ceros lo cual implica que no hay que realizar una limpieza de los datos, pero es de notar que la varianza es elevada, el valor minimo es cercano a 1000 y el valor maximo es cercano a 60.000 lo cual nos invita a pensar en como se podrían limpiar estas métricas, no porque las mismas estén mal tipeadas, sino mas bien porque es probable que nuestro modelo no requiera saber la informacion de atenciones medicas tan bajas de costo o tan altas, lo decidirá en parte el diagrama de caja y lo bien que trabae nuestro modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Datos que faltan\n",
    "\n",
    "Existen ciertas columnas que el metodo describe no es capaz de computar debido a que las mismas son columnas que se encuentran descriptas por strings. Para manejar estos datos lo que haremos será ver como estan compuestos los mismos, para eso podemos observar que en la columna \"smoker\" lo que se indica es si la persona es fumadora o no, esto se indica mediante las palabras \"yes\" o \"no\". Por lo tanto lo que podemos hacer es reemplazar todas las apariciones de yes por un 1 y todas las operaciones de no por un 0, esto lo podemos hacer de esta manera ya que es una variable categórica que presenta solo 2 estados posibles por lo que al asignarle un numero a cada una no le añadimos un peso consigo, no implica un ordenamiento de las categorías.\n",
    "\n",
    "Un caso similar ocurre para la columna sex que se clasifica en male or female.\n",
    "\n",
    "En cambio para el caso de los barrios ahí tenemos otro problema distinto debido a que ahora es una distribucion categótica pero con varias categorías, por lo que no podemos proceder de la misma manera que antes.\n",
    "\n",
    "A continuacion se muestra una manera de saber los posibles valores que pueden tomar cada una de estas columnas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "smoker\nno     1064\nyes     274\ndtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['smoker']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "sex\nfemale    662\nmale      676\ndtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['sex']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "region\nnortheast    324\nnorthwest    325\nsoutheast    364\nsouthwest    325\ndtype: int64"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['region']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "source": [
    "Primero resolvamos el problema de la columna smokers: \n",
    "\n",
    "Para esto lo que tenemos que hacer es reemplazar todos los yes por 1 y todos los no por 0:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['smoker']] = df[['smoker']].replace('yes',1)\n",
    "df[['smoker']] = df[['smoker']].replace('no',0)"
   ]
  },
  {
   "source": [
    "Para comprobar que haya funcionado como esperamos podemos comprobar a continuacion que describe ahora sí contempla la columna smoker y que la misma presenta una gran cantidad de no (0) y poca cantidad de yes (1) (la proporcion esta dada por la media que es aproximadamente 0.205), por lo tanto solo 1/5 de las personas son fumador\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               age          bmi     children       smoker       charges\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918     0.204783  13270.422265\n",
       "std      14.049960     6.098187     1.205493     0.403694  12110.011237\n",
       "min      18.000000    15.960000     0.000000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000     0.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000     0.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000     1.000000  63770.428010"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>39.207025</td>\n      <td>30.663397</td>\n      <td>1.094918</td>\n      <td>0.204783</td>\n      <td>13270.422265</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.049960</td>\n      <td>6.098187</td>\n      <td>1.205493</td>\n      <td>0.403694</td>\n      <td>12110.011237</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n      <td>15.960000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1121.873900</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27.000000</td>\n      <td>26.296250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4740.287150</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>39.000000</td>\n      <td>30.400000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>9382.033000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>51.000000</td>\n      <td>34.693750</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>16639.912515</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>64.000000</td>\n      <td>53.130000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>63770.428010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "Una vez realizado el estudio de la columna smoker procedemos a continuacion a realizar la limpieza de la columna sex, la mismas se clasifica en male o female, por lo que introduciremos el numero 1 en caso de que se trate de un hombre y el numero 0 si se tratara de una mujer:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sex']] = df[['sex']].replace('male',1)\n",
    "df[['sex']] = df[['sex']].replace('female',0)"
   ]
  },
  {
   "source": [
    "Para comprobar que todo funcionó de manera correcta podemos checkear el resultado de la instruccion describe:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               age          sex          bmi     children       smoker  \\\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000  1338.000000   \n",
       "mean     39.207025     0.505232    30.663397     1.094918     0.204783   \n",
       "std      14.049960     0.500160     6.098187     1.205493     0.403694   \n",
       "min      18.000000     0.000000    15.960000     0.000000     0.000000   \n",
       "25%      27.000000     0.000000    26.296250     0.000000     0.000000   \n",
       "50%      39.000000     1.000000    30.400000     1.000000     0.000000   \n",
       "75%      51.000000     1.000000    34.693750     2.000000     0.000000   \n",
       "max      64.000000     1.000000    53.130000     5.000000     1.000000   \n",
       "\n",
       "            charges  \n",
       "count   1338.000000  \n",
       "mean   13270.422265  \n",
       "std    12110.011237  \n",
       "min     1121.873900  \n",
       "25%     4740.287150  \n",
       "50%     9382.033000  \n",
       "75%    16639.912515  \n",
       "max    63770.428010  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n      <td>1338.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>39.207025</td>\n      <td>0.505232</td>\n      <td>30.663397</td>\n      <td>1.094918</td>\n      <td>0.204783</td>\n      <td>13270.422265</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.049960</td>\n      <td>0.500160</td>\n      <td>6.098187</td>\n      <td>1.205493</td>\n      <td>0.403694</td>\n      <td>12110.011237</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>15.960000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1121.873900</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>26.296250</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4740.287150</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>30.400000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>9382.033000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>51.000000</td>\n      <td>1.000000</td>\n      <td>34.693750</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>16639.912515</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>64.000000</td>\n      <td>1.000000</td>\n      <td>53.130000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>63770.428010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "De esta manera podemos notar que al encontrarse la media en torno al valor 0.5 podemos decir que los datos estan balanceados para esa columna.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Para el análisis de la variable en la columna region, como el numero de categorías es pequeño (4), podemos plantear una clasificacion mediante One Hot Encoding en lugar de utilizar embebbing, ya que de esta manera el análisis es simple y la cantidad de variables que agregamos no es tan grande como para necesitar realizar el cambio a embebbing.\n",
    "\n",
    "A continuación se detalla el procedimiento por el cual se realiza la codificacion mediante One Hot Encoding:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of columns Bs\n",
    "one_hot = pd.get_dummies(df['region'])\n",
    "# Drop column B as it is now encoded\n",
    "df = df.drop('region',axis = 1)\n",
    "# Join the encoded df\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "source": [
    "A continuación mostramos como quedó el dataset:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  sex     bmi  children  smoker      charges  northeast  northwest  \\\n",
       "0   19    0  27.900         0       1  16884.92400          0          0   \n",
       "1   18    1  33.770         1       0   1725.55230          0          0   \n",
       "2   28    1  33.000         3       0   4449.46200          0          0   \n",
       "3   33    1  22.705         0       0  21984.47061          0          1   \n",
       "4   32    1  28.880         0       0   3866.85520          0          1   \n",
       "\n",
       "   southeast  southwest  \n",
       "0          0          1  \n",
       "1          1          0  \n",
       "2          1          0  \n",
       "3          0          0  \n",
       "4          0          0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>charges</th>\n      <th>northeast</th>\n      <th>northwest</th>\n      <th>southeast</th>\n      <th>southwest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>0</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>1</td>\n      <td>16884.92400</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>1</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1725.55230</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>1</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>4449.46200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>1</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21984.47061</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>1</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3866.85520</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "Simplemente por una cuestion de orden pondremos la variable que no interesa hallar como la ultima columna del dataframe:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['age', 'sex', 'bmi', 'children', 'smoker', 'northeast', 'northwest', 'southeast', 'southwest', 'charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  sex     bmi  children  smoker  northeast  northwest  southeast  \\\n",
       "0   19    0  27.900         0       1          0          0          0   \n",
       "1   18    1  33.770         1       0          0          0          1   \n",
       "2   28    1  33.000         3       0          0          0          1   \n",
       "3   33    1  22.705         0       0          0          1          0   \n",
       "4   32    1  28.880         0       0          0          1          0   \n",
       "\n",
       "   southwest      charges  \n",
       "0          1  16884.92400  \n",
       "1          0   1725.55230  \n",
       "2          0   4449.46200  \n",
       "3          0  21984.47061  \n",
       "4          0   3866.85520  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>northeast</th>\n      <th>northwest</th>\n      <th>southeast</th>\n      <th>southwest</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>0</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>1</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>1</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>1</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>1</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3866.85520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "A continuación podemos ampliar la informacion aportada en esta etapa con algunos graficos de histogramas que nos permitan comprobar las distribuciones de edad bmi e hijos de las personas que formaron parte de este estudio."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan librerías para graficar.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfToPlot = df[['age', 'sex', 'bmi', 'children', 'smoker', 'charges']]\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=3)\n",
    "# for i, col in enumerate(dfToPlot.columns):\n",
    "#     sns.histplot(dfToPlot[col], ax=axes[int(i/3)][int(i%3)], bins=10)\n",
    "# axes[0][0].figure.set_size_inches(18, 10)\n",
    "# fig.suptitle('Histograms', fontsize=20)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "source": [
    "### De los gráficos anteriores podemos sacar algunas conclusiones: \n",
    "\n",
    "Las edades de los encuestados se encuentran bastante bien niveladas, sin presentar edades con valores muy superiores a otras lo cual es algo bueno para nuestro análisis. El sexo de las personas encuestadas tambien es algo que se enceuntra bien nivelado, presentandose la misma cantidad de personas mujeres que de hombres. La distribución de BMI en las personas se concentra en un valor cercano a 30 y disminuye hacia ambos lados. \n",
    "\n",
    "Las probabilidades decrecen al aumentar la cantidad de hijos. \n",
    "\n",
    "Existen mas personas no fumadoras que fumadoras en nuestro estudio.\n",
    "\n",
    "Y por ultimo tambien podemos notar que el numero de pagos disminuye a medida que aumenta el valor del mismo, por lo que son muy pocos frecuentes los casos en los que se requiera un pago cercano al valor 60.000.\n",
    "\n",
    "Para continuar con el análisis gráfico de la situación, debajo se encuentran los diagramas de cajas para las diferentes variables que conforman nuestro estudio, no se tienen en cuenta para ello las distribuciones con respecto a la region de las personas que se sabe que esta bastante bien nivelada la cantidad de personas que pertenecen a cada zona. Tampoco se grafican los diagramas de caja para las variables binomiales porque no nos aporta ninguna informacion este tipo de gráficos. Por ultimo se aclara que el diagrama para los charges es decir para los gastos de la atención médica se incorporan en un grafico aparte debido a que los valores son mucho mayores a los de las demás categorías."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(20, 10))\n",
    "# plt.ylabel('Variables')\n",
    "# plt.title(\"Boxplots\")\n",
    "# ax = sns.boxplot(data = dfToPlot[['age', 'bmi', 'children']], \n",
    "#   orient = 'h', \n",
    "#   palette = 'Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(20, 10))\n",
    "# plt.ylabel('Variables')\n",
    "# plt.title(\"Boxplots\")\n",
    "# ax = sns.boxplot(data = dfToPlot[['charges']], \n",
    "#   orient = 'h', \n",
    "#   palette = 'Set2')"
   ]
  },
  {
   "source": [
    "### Análisis de los boxplots:\n",
    "\n",
    "De los diagramas de caja podemos notar que existen algunos outliers con respecto a los valores de BMI que se deberá verificar como proceder con ellos (algo que se realiza mas adelante en el análisis) ademas se deberá tomar una decisión respecto de los puntos que conforman el charge es decir el gasto de la atención medica que son outliers, debido a que para esta variable el numero de outliers es muy grande.\n",
    "\n",
    "Por nuestro conocimiento del problema podemos deducir que la varianza en el precio de una atencion medica puede deberse a diferentes factores. De hecho nosotros mismos tenemos que diseñar la clasificación de manera tal de encontrar dichos factores, pero resulta comprensible que la varianza en el precio sea alta por lo que no consideramos que haga falta retirar dichos outliers de nuestro sistema, aunque de todas maneras si resulta indispensable considerar que existen debido a que la varianza en el pago es grande."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Grafico de correlacion de variables\n",
    "\n",
    "A continuación se muestran los diagramas de correlacion de variables que nos permiten tener una idea de la relacion entre las mismas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print a pairplot to check the relationships between strongly correlated features\n",
    "# pp = sns.pairplot(df[['age', 'sex', 'bmi', 'children', 'smoker', 'charges']])\n",
    "# pp = pp.map_lower(sns.regplot)\n",
    "# pp = pp.map_upper(sns.kdeplot);"
   ]
  },
  {
   "source": [
    "### Análisis del gráfico de correlacion de variables:\n",
    "\n",
    "Del gráfico anterior se pueden ver datos muy relevantes, si analizamos la fila correspondiente a la edad, veremos que no presenta correlacion frente al sexo lo cual nos habla de un estudio en principio bien realizado, tampoco varia demaisado con respecto al valor del bmi ni de la cantidad de hijos y la distribucion de edad para fumadores y no fumadores parece ser en principio muy parecida. Pero de todas maneras se puede ver de manera clara que existe una correlacion entre la edad de la persona y el charge se puede ver como los datos se ubican de forma tal que generan una pendiente notoria.\n",
    "\n",
    "De analizar la fila para sex podemos notar que la correlacion de sexo con bmi es muy pequeña, existe una distribucion parecida para las personas de sexo masculino o femenino, presentandose sí los valores de mayor BMI en hombres. \n",
    "\n",
    "Con respecto a la realcion entre seo y cantidad de hijos las distribuciones son muy similares y lo mismo ocurre con los fumadores, presentandose una ligera mayoria en los hombres fumadores respecto de las mujeres fumadoras, pero no es tan grande la diferencia. El sexo influye pero poco en los gastos de salud, presentandose un aumento del costo en el caso de los hombres.\n",
    "\n",
    "Con respecto a la fila de bmi podemos notar que existe una correlacion entre el bmi y el costo de salud medica, debido a que valores mayores de BMI tienden a presentar valores mayores de costos médicos.\n",
    "\n",
    "luego respecto de la cantidad de hijos se puede apreciar que las personas con mayor cantidad de hijos presentan valores menores de gastos medicos, algo que puede ser entendido debido a que estas personas quiza deban destinar parte de su dinero a sus familias en lugar de destinarlo a gastos medicos.\n",
    "\n",
    "Por ultimo la relacion entre los costos y si la persona es o no fumadora es muy grande, la correlacion existe de manera muy notoria en este caso, por lo que se ha de tener en cuenta para el análisis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Matriz de correlacion:\n",
    "\n",
    "Por último y para finalizar con el análisis de la situción se presenta a continuación una matriz que muestra la correlacion de las variables involucradas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation = df.corr()\n",
    "# sns.set(rc={'figure.figsize':(12,8)})\n",
    "# sns.heatmap(correlation,annot = True, linewidth=1, linecolor='w', cmap=\"Reds\")"
   ]
  },
  {
   "source": [
    "### Análisis de la matriz de correlacion\n",
    "\n",
    "Podemos ver en la matriz de correlacion que se encuentra arriba que los valores de correlacion se corresponden a las deducciónes que pudimos realizar sobre el modelo en base a los datos considerados de a pares en los diagramas de puntos. De esta manera podemos apreciar la fuerte correlacion que existe entre el precio pagado y el hecho de que la persona sea o no fumadora ademas de la influencia del bmi y la edad en el dinero que se destina a la salud. \n",
    "\n",
    "Una correalcion interesante que no podiamos ver en los graficos anteriores y ahora sí es la que existe entre el BMI y la region en la que viven las personas, principalmente para el caso de la region southeast en la cual la correlacion es muy fuerte respecto del BMI, este dato tal vez no es tan relevante para nuestro caso, pero podría servirnos si tuvieramos que postular valores si hubiera datos faltantes introducidos por el usuario."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "De esta manera hemos finalizado la etapa de limpieza y ordenamiento de los datos que nos permitirá a partir de ahora trabaja de manera mas estructurada con los mismos.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Primero separamos train de test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8,random_state=0)\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "source": [
    "## Declaramos la clase\n",
    "\n",
    "Dentro esta contendrá los metodos que necesitamos para correr nuestro modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostPredictor:\n",
    "    def __init__(self, df_train, df_validation, Epochs, train_labels, validation_labels):\n",
    "        \"\"\"CostPredictor\n",
    "\n",
    "        This is a class contains the most part of the methods needed for the cost predictor\n",
    "\n",
    "        \"\"\"\n",
    "        self.model = self.build_model(df_train)\n",
    "        self.EPOCHS = Epochs\n",
    "\n",
    "        self.df_train_norm = self.norm(df_train)\n",
    "        self.df_validation_norm = self.norm(df_validation)\n",
    "        self.train_labels = train_labels\n",
    "        self.validation_labels = validation_labels\n",
    "\n",
    "        self.train_stats = df_train.describe()\n",
    "        self.train_stats.pop(\"charges\")\n",
    "        self.train_stats = train_stats.transpose()\n",
    "\n",
    "\n",
    "    def norm(self, x):\n",
    "        return (x - self.train_stats['mean']) / self.train_stats['std']\n",
    "\n",
    "    def train_nn(self):\n",
    "        self.history = self.model.fit(self.df_train_norm, self.train_labels, epochs=self.EPOCHS,\n",
    "                    validation_data = (self.df_validation_x,self.df_validation_y), verbose=0, callbacks=[PrintDot(self.EPOCHS)])\n",
    "\n",
    "    def build_model(self, df_train):\n",
    "        initializer = tf.keras.initializers.GlorotNormal(seed=7) # We use an initializer to start always in the same position (because we are using the same seed)\n",
    "\n",
    "        model = keras.Sequential([\n",
    "        layers.Dense(2, activation='relu', input_shape=[len(df_train.keys())], kernel_initializer=initializer, bias_initializer=initializer),\n",
    "        layers.Dense(1, kernel_initializer=initializer)\n",
    "        ])\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "        name='Adam'\n",
    "        )\n",
    "\n",
    "        model.compile(loss='mse',\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['mae', 'mse'])\n",
    "        return model\n",
    "    \n",
    "    def get_summary(self):\n",
    "        self.model.summary()\n",
    "    \n",
    "    def get_hist(self):\n",
    "        hist = pd.DataFrame(self.history.history)\n",
    "        hist['epoch'] = self.history.epoch\n",
    "        hist.tail()\n",
    "\n",
    "    def validation_split(self, df_validation_norm):\n",
    "        df_validation_norm['charges'] = self.validation_labels\n",
    "\n",
    "        df_validation_norm_values = df_validation_norm.values\n",
    "\n",
    "        self.df_validation_x = df_validation_norm_values[:,:-1]\n",
    "        self.df_validation_y = df_validation_norm_values[:, -1].reshape(self.df_validation_x.shape[0], 1)\n",
    "\n",
    "\n",
    "    def create_history(self):\n",
    "        self.history = model.fit(df_train_norm, train_labels, epochs=EPOCHS,\n",
    "                    validation_data = (self.df_validation_x,self.df_validation_y), verbose=0, callbacks=[PrintDot(self.EPOCHS)])\n",
    "\n",
    "    def plot_history(self):\n",
    "        hist = pd.DataFrame(self.history.history)\n",
    "        hist['epoch'] = self.history.epoch\n",
    "\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Abs Error [MPG]')\n",
    "        plt.plot(hist['epoch'], hist['mae'],\n",
    "                label='Train Error')\n",
    "        plt.plot(hist['epoch'], hist['val_mae'],\n",
    "                label = 'Val Error')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "        plt.plot(hist['epoch'], hist['mse'],\n",
    "                label='Train Error')\n",
    "        plt.plot(hist['epoch'], hist['val_mse'],\n",
    "                label = 'Val Error')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def __init__(self, EPOCHS):\n",
    "        self.EPOCHS = EPOCHS\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.printProgressBar(float(epoch), int(self.EPOCHS),suffix = 'Complete', length = 50)\n",
    "    \n",
    "    def printProgressBar (self, iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\"):\n",
    "        \"\"\"\n",
    "        Call in a loop to create terminal progress bar\n",
    "        @params:\n",
    "            iteration   - Required  : current iteration (Int)\n",
    "            total       - Required  : total iterations (Int)\n",
    "            prefix      - Optional  : prefix string (Str)\n",
    "            suffix      - Optional  : suffix string (Str)\n",
    "            decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "            length      - Optional  : character length of bar (Int)\n",
    "            fill        - Optional  : bar fill character (Str)\n",
    "            printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "        \"\"\"\n",
    "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (float(iteration) / float(total)))\n",
    "        filledLength = int(length * iteration // total)\n",
    "        bar = fill * filledLength + '-' * (length - filledLength)\n",
    "        print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "        # Print New Line on Complete\n",
    "        if iteration == total-1: \n",
    "            print(f'\\r Trained 🧠🏃🏻‍♂️')"
   ]
  },
  {
   "source": [
    "## Ahora definimos el K-Folder (cross-validation)\n",
    "\n",
    "Decidimos utilizar kfolding debido a que tenemos un set de datos demasiado pequeño, de esta manera utilizando kfolding podemos disminuir la varianza de la metrica. \n",
    "\n",
    "De esta manera lo que haremos será definir los hiperparámetros fuera del Kfolding y cada vez que corramos nuestro modelo este performará dentro del Kfolding para comprobar al final de las iteraciones cual métrica obtengo en base a promediar la metrica de cada fold.\n",
    "\n",
    "Luego nuestro modelo sera una combinacion promedio de la salida de cada modelo. Vale recordar aqui que nos decidimos por este enfoque principalmente por la falta de datos y debido a que en este dataset realizar data aumentation seria complejo esta opcion es una opcion viable con sus correspondientes (y discutibles) pros y contras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = df_train[['charges']]\n",
    "# print(df_train)\n",
    "# df_train_without_target = df_train\n",
    "# df_train_without_target.pop('charges')\n",
    "\n",
    "# print(df_train_without_target)\n",
    "\n",
    "# # here we need to convert the dataframe into k dataframes for x_train, x_validation, y_validation and y_train\n",
    "\n",
    "# EPOCHS = 100\n",
    "\n",
    "#     # predictor = CostPredictor(X_train, X_validation, EPOCHS, Y_train, Y_validation)\n",
    "\n",
    "#     # predictor.get_summary()\n",
    "\n",
    "#     # predictor.validation_split(df_validation_norm)\n",
    "\n",
    "#     # predictor.train_nn()\n",
    "\n",
    "#     # predictor.get_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folding(df):\n",
    "    \"\"\"\n",
    "    Función que dado un dataframe realiza un k-folding con k=5.\n",
    "    Recibe:\n",
    "        Dataframe\n",
    "    Devuelve:\n",
    "        Lista que contiene a las matrices de confusión para cada k_i paso.\n",
    "    \"\"\"\n",
    "    EPOCHS = 100\n",
    "    kf = KFold(n_splits = 3, random_state=7 , shuffle=True)\n",
    "    sub_sets = kf.split(df)\n",
    "    for train_index, validation_index in sub_sets:\n",
    "        # Here we split the data \n",
    "        train_df = df.iloc[train_index]\n",
    "        validation_df = df.iloc[validation_index]\n",
    "        # After we split the train_df in target_train and no_charges_train dataframes\n",
    "\n",
    "        df_train_target = train_df['charges']\n",
    "        df_train_no_charges = train_df\n",
    "        df_train_no_charges.pop('charges')\n",
    "\n",
    "        df_validation_target = validation_df['charges']\n",
    "        df_validation_no_charges = validation_df\n",
    "        df_validation_no_charges.pop('charges')\n",
    "\n",
    "        predictor = CostPredictor(df_train_no_charges, df_validation_no_charges, EPOCHS, df_train_target, df_validation_target)\n",
    "        predictor.get_summary()\n",
    "        predictor.validation_split(df_validation_norm)\n",
    "        predictor.train_nn()\n",
    "        predictor.get_hist()\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'CostPredictor' object has no attribute 'train_stats'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-7126a59fd1c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mk_folding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-222-16dd9ccd739c>\u001b[0m in \u001b[0;36mk_folding\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdf_validation_no_charges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'charges'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCostPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train_no_charges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_validation_no_charges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_validation_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_validation_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-220-3b9a189b69bb>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df_train, df_validation, Epochs, train_labels, validation_labels)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEpochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_train_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_validation_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-220-3b9a189b69bb>\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_stats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CostPredictor' object has no attribute 'train_stats'"
     ]
    }
   ],
   "source": [
    "k_folding(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}