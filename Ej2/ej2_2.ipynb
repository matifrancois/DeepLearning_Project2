{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "## Implementacion de una red neuronal que incorpora una regresión lineal.\n",
    "\n",
    "### Importamos los datos en un dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "source": [
    "Breve Análisis del dataset\n",
    "Mostramos primero algunos valores de nuestro dataset.\n",
    "\n",
    "Luego los nombres de las columnas de nuestro dataframe\n",
    "\n",
    "Y para finalizar tambien mostramos el tamaño del dataframe con el que trabajaremos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Next the first rows of our dataset are showed: \\n\")\n",
    "print(df.head())\n",
    "print(\"\\nThe colums of our dataset refears to: \\n\"+str(df.columns) + \"\\n\")\n",
    "print(\"the size of the dataframe is: \\n \" + str(df.shape) + \"\\n\")"
   ]
  },
  {
   "source": [
    "Con la siguiente linea nos fijamos los tipos de datos que tenemos presentes en cada columna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "Verificamos la cantidad de datos nulos presentes en nuestro dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "source": [
    "Podemos utilizar el método describe para examinar como son los valores que se presentan dentro del dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "### Breve análisis del dataframe\n",
    "\n",
    "De ver los valores que devuelve describe podemos darnos cuenta que como los valores minimos de edad no son 0 entonces no hay datos nulos ni ceros que podrían se considerados invalidos en esa columna, de hecho el valor maximo es 64 por lo que podríamos plantear a priori que no es necesario una limpieza de los datos para esa columna.\n",
    "Luego en el BMI vemos que no existen valores iguales a 0 de hecho el valor minimo es 15 lo cual es un valor posible y el valor maximo es 53 lo cual es un valor muy alto pero al ser el valor mas alto de nuestro dataframe podríamos considerar que esta \"bien\" y que luego será el diagrama de caja el que nos termine de definir si pertenece o no al grupo de los outlayers, pero en principio uno podría afirmar que el valor es posible en un humano, muy poco saludable pero posible. \n",
    "La cantidad de hijos tambien es un parámetro que no presenta valores nulos ni invalidos, debido a que el minimo es cero el cual es un valor perfectamente posible y el valor maximo es 5 lo cual tambien parecería ser un valor esperado, por lo tanto no es necesario realizar ningun tipo de limpieza de datos sobre el mismo.\n",
    "Los charges que son sobrados por la atencion medica recibida en principio tampoco tienen valores nulos ni ceros lo cual implica que no hay que realizar una limpieza de los datos, pero es de notar que la varianza es elevada, el valor minimo es cercano a 1000 y el valor maximo es cercano a 60.000 lo cual nos invita a pensar en como se podrían limpiar estas métricas, no porque las mismas estén mal tipeadas, sino mas bien porque es probable que nuestro modelo no requiera saber la informacion de atenciones medicas tan bajas de costo o tan altas, lo decidirá en parte el diagrama de caja y lo bien que trabae nuestro modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Datos que faltan\n",
    "\n",
    "Existen ciertas columnas que el metodo describe no es capaz de computar debido a que las mismas son columnas que se encuentran descriptas por strings. Para manejar estos datos lo que haremos será ver como estan compuestos los mismos, para eso podemos observar que en la columna \"smoker\" lo que se indica es si la persona es fumadora o no, esto se indica mediante las palabras \"yes\" o \"no\". Por lo tanto lo que podemos hacer es reemplazar todas las apariciones de yes por un 1 y todas las operaciones de no por un 0, esto lo podemos hacer de esta manera ya que es una variable categórica que presenta solo 2 estados posibles por lo que al asignarle un numero a cada una no le añadimos un peso consigo, no implica un ordenamiento de las categorías.\n",
    "\n",
    "Un caso similar ocurre para la columna sex que se clasifica en male or female.\n",
    "\n",
    "En cambio para el caso de los barrios ahí tenemos otro problema distinto debido a que ahora es una distribucion categótica pero con varias categorías, por lo que no podemos proceder de la misma manera que antes.\n",
    "\n",
    "A continuacion se muestra una manera de saber los posibles valores que pueden tomar cada una de estas columnas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['smoker']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['sex']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurances a particular column\n",
    "occur = df.groupby(['region']).size()\n",
    "  \n",
    "# diplay occurances of a particular column\n",
    "display(occur)"
   ]
  },
  {
   "source": [
    "Primero resolvamos el problema de la columna smokers: \n",
    "\n",
    "Para esto lo que tenemos que hacer es reemplazar todos los yes por 1 y todos los no por 0:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['smoker']] = df[['smoker']].replace('yes',1)\n",
    "df[['smoker']] = df[['smoker']].replace('no',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para comprobar que haya funcionado como esperamos podemos comprobar a continuacion que describe ahora sí contempla la columna smoker y que la misma presenta una gran cantidad de no (0) y poca cantidad de yes (1) (la proporcion esta dada por la media que es aproximadamente 0.205), por lo tanto solo 1/5 de las personas son fumador\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "Una vez realizado el estudio de la columna smoker procedemos a continuacion a realizar la limpieza de la columna sex, la mismas se clasifica en male o female, por lo que introduciremos el numero 1 en caso de que se trate de un hombre y el numero 0 si se tratara de una mujer:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sex']] = df[['sex']].replace('male',1)\n",
    "df[['sex']] = df[['sex']].replace('female',0)"
   ]
  },
  {
   "source": [
    "Para comprobar que todo funcionó de manera correcta podemos checkear el resultado de la instruccion describe:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "De esta manera podemos notar que al encontrarse la media en torno al valor 0.5 podemos decir que los datos estan balanceados para esa columna."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Para el análisis de la variable en la columna region, como el numero de categorías es pequeño (4), podemos plantear una clasificacion mediante One Hot Encoding en lugar de utilizar embebbing, ya que de esta manera el análisis es simple y la cantidad de variables que agregamos no es tan grande como para necesitar realizar el cambio a embebbing.\n",
    "\n",
    "A continuación se detalla el procedimiento por el cual se realiza la codificacion mediante One Hot Encoding:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one hot encoding of columns Bs\n",
    "one_hot = pd.get_dummies(df['region'])\n",
    "# Drop column B as it is now encoded\n",
    "df = df.drop('region',axis = 1)\n",
    "# Join the encoded df\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "source": [
    "A continuación mostramos como quedó el dataset:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simplemente por una cuestion de orden pondremos la variable que no interesa hallar como la ultima columna del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['age', 'sex', 'bmi', 'children', 'smoker', 'northeast', 'northwest', 'southeast', 'southwest', 'charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "A continuación podemos ampliar la informacion aportada en esta etapa con algunos graficos de histogramas que nos permitan comprobar las distribuciones de edad bmi e hijos de las personas que formaron parte de este estudio."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan librerías para graficar.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfToPlot = df[['age', 'sex', 'bmi', 'children', 'smoker', 'charges']]\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=3)\n",
    "# for i, col in enumerate(dfToPlot.columns):\n",
    "#     sns.histplot(dfToPlot[col], ax=axes[int(i/3)][int(i%3)], bins=10)\n",
    "# axes[0][0].figure.set_size_inches(18, 10)\n",
    "# fig.suptitle('Histograms', fontsize=20)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "source": [
    "### De los gráficos anteriores podemos sacar algunas conclusiones: \n",
    "\n",
    "Las edades de los encuestados se encuentran bastante bien niveladas, sin presentar edades con valores muy superiores a otras lo cual es algo bueno para nuestro análisis. El sexo de las personas encuestadas tambien es algo que se enceuntra bien nivelado, presentandose la misma cantidad de personas mujeres que de hombres. La distribución de BMI en las personas se concentra en un valor cercano a 30 y disminuye hacia ambos lados. \n",
    "\n",
    "Las probabilidades decrecen al aumentar la cantidad de hijos. \n",
    "\n",
    "Existen mas personas no fumadoras que fumadoras en nuestro estudio.\n",
    "\n",
    "Y por ultimo tambien podemos notar que el numero de pagos disminuye a medida que aumenta el valor del mismo, por lo que son muy pocos frecuentes los casos en los que se requiera un pago cercano al valor 60.000.\n",
    "\n",
    "Para continuar con el análisis gráfico de la situación, debajo se encuentran los diagramas de cajas para las diferentes variables que conforman nuestro estudio, no se tienen en cuenta para ello las distribuciones con respecto a la region de las personas que se sabe que esta bastante bien nivelada la cantidad de personas que pertenecen a cada zona. Tampoco se grafican los diagramas de caja para las variables binomiales porque no nos aporta ninguna informacion este tipo de gráficos. Por ultimo se aclara que el diagrama para los charges es decir para los gastos de la atención médica se incorporan en un grafico aparte debido a que los valores son mucho mayores a los de las demás categorías."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(20, 10))\n",
    "# plt.ylabel('Variables')\n",
    "# plt.title(\"Boxplots\")\n",
    "# ax = sns.boxplot(data = dfToPlot[['age', 'bmi', 'children']], \n",
    "#   orient = 'h', \n",
    "#   palette = 'Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(20, 10))\n",
    "# plt.ylabel('Variables')\n",
    "# plt.title(\"Boxplots\")\n",
    "# ax = sns.boxplot(data = dfToPlot[['charges']], \n",
    "#   orient = 'h', \n",
    "#   palette = 'Set2')"
   ]
  },
  {
   "source": [
    "### Análisis de los boxplots:\n",
    "\n",
    "De los diagramas de caja podemos notar que existen algunos outliers con respecto a los valores de BMI que se deberá verificar como proceder con ellos (algo que se realiza mas adelante en el análisis) ademas se deberá tomar una decisión respecto de los puntos que conforman el charge es decir el gasto de la atención medica que son outliers, debido a que para esta variable el numero de outliers es muy grande.\n",
    "\n",
    "Por nuestro conocimiento del problema podemos deducir que la varianza en el precio de una atencion medica puede deberse a diferentes factores. De hecho nosotros mismos tenemos que diseñar la clasificación de manera tal de encontrar dichos factores, pero resulta comprensible que la varianza en el precio sea alta por lo que no consideramos que haga falta retirar dichos outliers de nuestro sistema, aunque de todas maneras si resulta indispensable considerar que existen debido a que la varianza en el pago es grande."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Grafico de correlacion de variables\n",
    "\n",
    "A continuación se muestran los diagramas de correlacion de variables que nos permiten tener una idea de la relacion entre las mismas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print a pairplot to check the relationships between strongly correlated features\n",
    "# pp = sns.pairplot(df[['age', 'sex', 'bmi', 'children', 'smoker', 'charges']])\n",
    "# pp = pp.map_lower(sns.regplot)\n",
    "# pp = pp.map_upper(sns.kdeplot);"
   ]
  },
  {
   "source": [
    "### Análisis del gráfico de correlacion de variables:\n",
    "\n",
    "Del gráfico anterior se pueden ver datos muy relevantes, si analizamos la fila correspondiente a la edad, veremos que no presenta correlacion frente al sexo lo cual nos habla de un estudio en principio bien realizado, tampoco varia demaisado con respecto al valor del bmi ni de la cantidad de hijos y la distribucion de edad para fumadores y no fumadores parece ser en principio muy parecida. Pero de todas maneras se puede ver de manera clara que existe una correlacion entre la edad de la persona y el charge se puede ver como los datos se ubican de forma tal que generan una pendiente notoria.\n",
    "\n",
    "De analizar la fila para sex podemos notar que la correlacion de sexo con bmi es muy pequeña, existe una distribucion parecida para las personas de sexo masculino o femenino, presentandose sí los valores de mayor BMI en hombres. \n",
    "\n",
    "Con respecto a la realcion entre seo y cantidad de hijos las distribuciones son muy similares y lo mismo ocurre con los fumadores, presentandose una ligera mayoria en los hombres fumadores respecto de las mujeres fumadoras, pero no es tan grande la diferencia. El sexo influye pero poco en los gastos de salud, presentandose un aumento del costo en el caso de los hombres.\n",
    "\n",
    "Con respecto a la fila de bmi podemos notar que existe una correlacion entre el bmi y el costo de salud medica, debido a que valores mayores de BMI tienden a presentar valores mayores de costos médicos.\n",
    "\n",
    "luego respecto de la cantidad de hijos se puede apreciar que las personas con mayor cantidad de hijos presentan valores menores de gastos medicos, algo que puede ser entendido debido a que estas personas quiza deban destinar parte de su dinero a sus familias en lugar de destinarlo a gastos medicos.\n",
    "\n",
    "Por ultimo la relacion entre los costos y si la persona es o no fumadora es muy grande, la correlacion existe de manera muy notoria en este caso, por lo que se ha de tener en cuenta para el análisis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Matriz de correlacion:\n",
    "\n",
    "Por último y para finalizar con el análisis de la situción se presenta a continuación una matriz que muestra la correlacion de las variables involucradas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation = df.corr()\n",
    "# sns.set(rc={'figure.figsize':(12,8)})\n",
    "# sns.heatmap(correlation,annot = True, linewidth=1, linecolor='w', cmap=\"Reds\")"
   ]
  },
  {
   "source": [
    "### Análisis de la matriz de correlacion\n",
    "\n",
    "Podemos ver en la matriz de correlacion que se encuentra arriba que los valores de correlacion se corresponden a las deducciónes que pudimos realizar sobre el modelo en base a los datos considerados de a pares en los diagramas de puntos. De esta manera podemos apreciar la fuerte correlacion que existe entre el precio pagado y el hecho de que la persona sea o no fumadora ademas de la influencia del bmi y la edad en el dinero que se destina a la salud. \n",
    "\n",
    "Una correalcion interesante que no podiamos ver en los graficos anteriores y ahora sí es la que existe entre el BMI y la region en la que viven las personas, principalmente para el caso de la region southeast en la cual la correlacion es muy fuerte respecto del BMI, este dato tal vez no es tan relevante para nuestro caso, pero podría servirnos si tuvieramos que postular valores si hubiera datos faltantes introducidos por el usuario."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "De esta manera hemos finalizado la etapa de limpieza y ordenamiento de los datos que nos permitirá a partir de ahora trabaja de manera mas estructurada con los mismos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Separamos el data set en train-valid y test\n",
    "\n",
    "Lo hacemos de esta manera con random_state = 0 ya que de esta manera le estamos dando el valor 0 como semilla al proceso random que va dentro de df.sample entonces de esta manera podemos lograr que los datos de train y de test sean siempre los mismos lo cual nos permite tener cierta repetitividad.\n",
    "Tambien dividimos la validacion aqui para de vuelta lograr asegurarnos que podemos obtener una repetitividad, luego cuando se implementa un kfolding de todos estos métodos podemos volver a darle la arbitrariedad que necesitamos a la seleccion de validation train y test."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8,random_state=0)\n",
    "df_validation = df_train.sample(frac=0.2, random_state=0)\n",
    "df_test = df.drop(df_train.index)\n",
    "df_train = df_train.drop(df_validation.index)\n",
    "print(df_train.describe())\n",
    "print(df_test.describe())\n",
    "print(df_validation.describe())"
   ]
  },
  {
   "source": [
    "A continuacion se calculan las estadísticas necesarias para poder luego normalizar las variables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = df_train.describe()\n",
    "train_stats.pop(\"charges\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats\n",
    "\n",
    "print(train_stats)\n",
    "\n",
    "print(df_train.describe())\n",
    "print(df_validation.describe())\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df_train.pop('charges')\n",
    "valid_labels = df_validation.pop('charges')\n",
    "test_labels = df_test.pop('charges')"
   ]
  },
  {
   "source": [
    "A continuación definimos una funcion que nos permite normalizar los datos que se pasan a la misma, pasaremos ambos dataframes por ella, tanto el dataframe de train como el de test.\n",
    "\n",
    "Tambien es importante una vez que tengamos nuestro modelo entrenado pasar los valores que se quieran calcular con el modelo por esta funcion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "df_train_norm = norm(df_train)\n",
    "df_validation_norm = norm(df_validation)\n",
    "df_test_norm = norm(df_test)\n",
    "\n",
    "print(df_train_norm.describe())\n",
    "print(df_validation_norm.describe())\n",
    "print(df_test_norm.describe())\n",
    "\n"
   ]
  },
  {
   "source": [
    "A continuación definimos el modelo que utilizaremos:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=7) # We use an initializer to start always in the same position (because we are using the same seed)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu', input_shape=[len(df_train.keys())], kernel_initializer=initializer),\n",
    "    layers.Dense(1, kernel_initializer=initializer)\n",
    "  ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_norm_values = df_validation_norm.values\n",
    "\n",
    "df_validation_x = df_validation_norm_values[:,:-1]\n",
    "df_validation_y = df_validation_norm_values[:, -1].reshape(df_validation_x.shape[0], 1)\n",
    "\n",
    "\n",
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "\n",
    "EPOCHS = 4000\n",
    "\n",
    "train_labels = df_train_norm.pop('charges')\n",
    "print(df_train_norm.describe())\n",
    "print(train_labels)\n",
    "\n",
    "history = model.fit(df_train_norm, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error [MPG]')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "EPOCHS = 4000\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def __init__(self, EPOCHS):\n",
    "        self.EPOCHS = EPOCHS\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.printProgressBar(float(epoch), int(self.EPOCHS),suffix = 'Complete', length = 50)\n",
    "    \n",
    "    def printProgressBar (self, iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "        \"\"\"\n",
    "        Call in a loop to create terminal progress bar\n",
    "        @params:\n",
    "            iteration   - Required  : current iteration (Int)\n",
    "            total       - Required  : total iterations (Int)\n",
    "            prefix      - Optional  : prefix string (Str)\n",
    "            suffix      - Optional  : suffix string (Str)\n",
    "            decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "            length      - Optional  : character length of bar (Int)\n",
    "            fill        - Optional  : bar fill character (Str)\n",
    "            printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "        \"\"\"\n",
    "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (float(iteration) / float(total)))\n",
    "        filledLength = int(length * iteration // total)\n",
    "        bar = fill * filledLength + '-' * (length - filledLength)\n",
    "        print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "        # Print New Line on Complete\n",
    "        if iteration == total: \n",
    "            print()\n",
    "    \n",
    "\n",
    "history = model.fit(\n",
    "  df_train_norm, train_labels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot(EPOCHS)])"
   ]
  }
 ]
}