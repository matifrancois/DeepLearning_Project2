1) epochs
2) learning rate
3) Explicar que como no hay overfitting entonces usar early stopping es al pedo
4) Explicar por que no usariamos drop out (1 sola neurona) 
5) Explicar por que no usariamos regularizacion (no hay overfitting)
6) Explicar por que no usariamos batch normalization (porque al tener una sola neurona no tiene sentido usarlo)


Parte 1:

☐ terminar el testeo del 1

✔ Rehacer el 1 con 1 sola neurona @done(21-05-30 22:43)

☐ Comprobar si mejora sacando los outliers

✔ Poner tensorboard @done(21-05-30 22:44)



Parte 2:

☐ Hacer que funcione mejor con features polinomiales

Parte 3: 

☐ Buscar mas casos y ver si mejora para alguno



Mañana:

☐ Checkear tensorboard